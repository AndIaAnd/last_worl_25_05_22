{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машины опорных векторов\n",
    "Машина опорНЬiх векторов (Support Vector Machine - SVМ) - это классификатор,\n",
    "определенный с использованием гиперплоскости, разделяющей\n",
    "классы. Разделяющая rиперruюскость представляет собой N-мерную версию\n",
    "прямой линии. При условии, что в задаче бинарной классификации задан\n",
    "маркированный обучающий набор данных, SVМ находит оптимальную\n",
    "гиперплоскость, которая делит данные на два класса. Этот метод легко распространяется\n",
    "на задачу с N классами.\n",
    "Рассмотрим двумерный случай с двумя классами точек. Таким образом,\n",
    "мы будем иметь дело только с точками и прямыми, расположенными на\n",
    "двумерной плоскости, что значительно проще, чем визуализировать векторы\n",
    "и гиперплоскости в пространстве большей размерности. Конечно же, это\n",
    "упрощенная версия задачи SVМ, но очень важно рассмотреть и визуализировать\n",
    "данный случай, прежде чем переходить к наборам данных более высоких\n",
    "размерностей.\n",
    "Рассмотрим рис. 2.8.\n",
    "Как видите, мы имеем два класса точек и хотим найти оптимальную гиперплоскость,\n",
    "разделяющую эти классы. Однако что именно следует считать\n",
    "критерием оптимальности? На рисунке сплошная линия представляет\n",
    "оптимальную гиперплоскость. Можно провести множество прямых линий,\n",
    "разделяющих данные классы точек, но эта линия является наилучшим разделителем,\n",
    "поскольку она максимизирует расстояния, на которые точки\n",
    "удалены от разделяющей их линии. Точки, расположенные на пунктирных\n",
    "линиях, называются опорными векторами. Расстояние между двумя пунктирными\n",
    "линиями называется максимальным Зазором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация данных о доходах\n",
    "с помощью машин опорных векторов\n",
    "Создадим классификатор в виде машины опорных векторов, предназначенный\n",
    "для прогнозирования границ дохода заданного физического лица на\n",
    "основе 14 атрибутов. Нашей целью является выяснение условий, при которых\n",
    "ежегодный доход человека превышает $50000 или меньше этой величины.\n",
    "Следовательно, мы имеем дело с задачей бинарной классификации. Мы\n",
    "воспользуемся набором данных о доходах, предоставленным Бюро переписи\n",
    "населения США по адресу https: //archive .ics.uc i.edu /ml /da tasets/\n",
    "Census+ Income. Следует отметить одну особенность этого набора, которая\n",
    "заключается в том, что каждая точка данных представляет собой сочетание\n",
    "текста и чисел. Мы не можем использовать эти данные в необработанном\n",
    "виде, поскольку алгоритмам неизвестно, как обрабатывать слова. Мы также\n",
    "не можем преобразовать все данные, используя кодирование меток, поскольку\n",
    "числовые данные также содержат ценную информацию . Следовательно,\n",
    "чтобы создать эффективный классификатор, мы должны использовать комбинацию\n",
    "кодировщиков меток и необработанных числовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# входные файлы\n",
    "input_file = 'income_data.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаемые из файла данные нужно подготовить к классификации, подвергнув\n",
    "их предварительной обработке. Для каждою класса мы будем использовать\n",
    "не более 25000 точек данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение данных\n",
    "X = []\n",
    "y = []\n",
    "count_class1 = 0\n",
    "count_class2 = 0\n",
    "max_datapoints = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if count_class1 >= max_datapoints and count_class2 >= max_datapoints:\n",
    "            break\n",
    "        \n",
    "        if '?' in line:\n",
    "            continue\n",
    "        \n",
    "        data = line[:-1].split(', ')\n",
    "        \n",
    "        if data[-1] == '<=50K' and count_class1 < max_datapoints:\n",
    "            X.append(data)\n",
    "            count_class1 += 1\n",
    "            \n",
    "        if data[-1] == '>50K' and count_class2 < max_datapoints:\n",
    "            X.append(data)\n",
    "            count_class2 += 1\n",
    "# Преобразование в массив numpy \n",
    "X = np.array(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем список в массив array, чтобы его можно было использовать\n",
    "в качестве входных данных функций sklearn\n",
    "Если атрибут - строка, то он нуждается в кодировании. Если атрибут -\n",
    "число, мы можем оставить его в том виде, как он есть. Заметьте, что в конечном\n",
    "счете мы получим несколько кодировщиков меток, которые нам нужно\n",
    "будет отслеживать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование стоковых данных в числовые\n",
    "label_encoder = []\n",
    "X_encoded = np.empty(X.shape)\n",
    "for i, item in enumerate(X[0]):\n",
    "    if item.isdigit():\n",
    "        X_encoded[:, 1] = X[:, i]\n",
    "    else:\n",
    "        label_encoder.append(preprocessing.LabelEncoder())\n",
    "        X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 56.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape () instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\D395~1\\AppData\\Local\\Temp/ipykernel_11520/2792118127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0minput_data_encoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0minput_data_encoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \"\"\"\n\u001b[0;32m    132\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;31m# transform of empty array is empty array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    922\u001b[0m         \u001b[1;34m\"y should be a 1d array, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m         \"got an array of shape {} instead.\".format(shape))\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape () instead."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Input file containing data\n",
    "input_file = 'income_data.txt'\n",
    "\n",
    "# Read the data\n",
    "X = []\n",
    "y = []\n",
    "count_class1 = 0\n",
    "count_class2 = 0\n",
    "max_datapoints = 25000\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if count_class1 >= max_datapoints and count_class2 >= max_datapoints:\n",
    "            break\n",
    "\n",
    "        if '?' in line:\n",
    "            continue\n",
    "\n",
    "        data = line[:-1].split(', ')\n",
    "\n",
    "        if data[-1] == '<=50K' and count_class1 < max_datapoints:\n",
    "            X.append(data)\n",
    "            count_class1 += 1\n",
    "\n",
    "        if data[-1] == '>50K' and count_class2 < max_datapoints:\n",
    "            X.append(data)\n",
    "            count_class2 += 1\n",
    "\n",
    "# Convert to numpy array\n",
    "X = np.array(X)\n",
    "\n",
    "# Convert string data to numerical data\n",
    "label_encoder = [] \n",
    "X_encoded = np.empty(X.shape)\n",
    "for i,item in enumerate(X[0]):\n",
    "    if item.isdigit(): \n",
    "        X_encoded[:, i] = X[:, i]\n",
    "    else:\n",
    "        label_encoder.append(preprocessing.LabelEncoder())\n",
    "        X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i])\n",
    "\n",
    "X = X_encoded[:, :-1].astype(int)\n",
    "y = X_encoded[:, -1].astype(int)\n",
    "\n",
    "# Create SVM classifier\n",
    "classifier = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "classifier = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "# Compute the F1 score of the SVM classifier\n",
    "f1 = cross_val_score(classifier, X, y, scoring='f1_weighted', cv=3)\n",
    "print(\"F1 score: \" + str(round(100*f1.mean(), 2)) + \"%\")\n",
    "\n",
    "# Predict output for a test datapoint\n",
    "input_data = ['37', 'Private', '215646', 'HS-grad', '9', 'Never-married', 'Handlers-cleaners', 'Not-in-family', 'White', 'Male', '0', '0', '40', 'United-States']\n",
    "\n",
    "# Encode test datapoint\n",
    "input_data_encoded = [-1] * len(input_data)\n",
    "count = 0\n",
    "for i, item in enumerate(input_data):\n",
    "    if item.isdigit():\n",
    "        input_data_encoded[i] = int(input_data[i])\n",
    "    else:\n",
    "        input_data_encoded[i] = int(label_encoder[count].transform(input_data[i]))\n",
    "        count += 1 \n",
    "\n",
    "input_data_encoded = np.array(input_data_encoded)\n",
    "\n",
    "# Run classifier on encoded datapoint and print output\n",
    "predicted_class = classifier.predict(input_data_encoded)\n",
    "print(label_encoder[-1].inverse_transform(predicted_class)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
